{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "spam detector .ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gdg-ml-team/DevFest19/blob/master/spam_detector_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHVYvIqNn_0R",
        "colab_type": "text"
      },
      "source": [
        "# Deep learning for Text Classification\n",
        "\n",
        "In this notebook I'll be using the neural networks algorithm to create a model that can classify dataset Messages as spam or not spam based on the dataset that we'll give to the model. If you don't know what is the spammy message look like it usually contain words like 'win', 'cash', 'money', 'winner' ,'free'..etc and it designed to be notice and tempt you to open it.And sometimes it contains CAPTIAL WORDS and alot of exclamation marks!!!. Our mission here is to train a model to predict spammy messages for us!\n",
        "\n",
        "Identify spam messages is **a binary classification problem** as messages are classified as either 'Spam' or 'Not Spam' and nothing else. Also, this is **a supervised learning problem**, as we will be feeding a labelled dataset into the model, that it can learn from, to make future predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrMtw5xwn_0S",
        "colab_type": "text"
      },
      "source": [
        "## Step 1.1: Understanding our dataset\n",
        "\n",
        "\n",
        "Import the dataset into a **pandas** dataframe using the `.read_csv()` method. You can access it using the filepath `\"spam.csv\"`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T1SssNqn_0T",
        "colab_type": "text"
      },
      "source": [
        "The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU9ZDmU2n_0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46mPGvf0n_0X",
        "colab_type": "code",
        "colab": {},
        "outputId": "c50d7870-9e61-4c3b-c74d-ea8c5e7937b8"
      },
      "source": [
        "df = pd.read_csv(\"spam.csv\", encoding=\"iso-8859-1\")\n",
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1                                                 v2 Unnamed: 2  \\\n",
              "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
              "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
              "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
              "5  spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
              "6   ham  Even my brother is not like to speak with me. ...        NaN   \n",
              "7   ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
              "8  spam  WINNER!! As a valued network customer you have...        NaN   \n",
              "9  spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
              "\n",
              "  Unnamed: 3 Unnamed: 4  \n",
              "0        NaN        NaN  \n",
              "1        NaN        NaN  \n",
              "2        NaN        NaN  \n",
              "3        NaN        NaN  \n",
              "4        NaN        NaN  \n",
              "5        NaN        NaN  \n",
              "6        NaN        NaN  \n",
              "7        NaN        NaN  \n",
              "8        NaN        NaN  \n",
              "9        NaN        NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvQRkQl6n_0c",
        "colab_type": "text"
      },
      "source": [
        "As we see above there are five columns and only two have values the first one called `v1` and the second called `v2`\n",
        "so first we have to get only the two columns that contain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGhzeTYJn_0d",
        "colab_type": "code",
        "colab": {},
        "outputId": "64a4c636-e3a6-4e75-e16d-a240f42842d6"
      },
      "source": [
        "df = df[[\"v1\",\"v2\"]]\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1                                                 v2\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8xOpmQhn_0f",
        "colab_type": "text"
      },
      "source": [
        "Good now we have two columns v1 and v2 but there names are meaningless so let's rename them `label` and `message`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnzWNemsn_0g",
        "colab_type": "code",
        "colab": {},
        "outputId": "c4060e0c-0eb9-4837-dcd3-67e10c66cd5a"
      },
      "source": [
        "df.rename(columns={\"v1\":\"label\",\"v2\":\"message\"},inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                            message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALK_B1L4n_0j",
        "colab_type": "text"
      },
      "source": [
        "## Step 1.2: Data Preprocessing\n",
        "Now that we have a basic understanding of what our dataset looks like, lets convert our labels to binary variables(we make binary classification), 0 to represent 'ham'(not spam) and 1 to represent 'spam' for ease of computation.\n",
        "\n",
        "Our model would still be able to make predictions if we left our labels as strings but we could have issues later when calculating performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfthWVCvn_0j",
        "colab_type": "code",
        "colab": {},
        "outputId": "4a7528c0-09ba-4bbf-ebaf-5b4ef598f173"
      },
      "source": [
        "df['label'] = df.label.map({\"ham\":0,\"spam\":1})\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQxlZr9Hn_0m",
        "colab_type": "text"
      },
      "source": [
        "## Step 2.1: Bag of words\n",
        "\n",
        "What we have here in our dataset is a large collection of text data (5,572 rows of data). Most ML algorithms rely on **numerical data** to be fed into them as input, and **our dataset are usually text**.\n",
        "\n",
        "Here we'd like to introduce the **Bag of Words(BoW)** concept which is a term used to specify the problems that have a collection of text data that needs to be worked with. The basic idea of BoW is to take a piece of text and count the frequency of the words in that text. It is important to note that the BoW concept treats each word individually and the order in which the words occur does not matter.\n",
        "\n",
        "Using a process which we will go through now, we can convert a collection of documents to a matrix, with each document being a row and each word(token) being the column, and the corresponding (row,column) values being the frequency of occurrence of each word or token in that document.\n",
        "\n",
        "For example:\n",
        "\n",
        "Lets say we have 4 documents as follows:\n",
        "\n",
        "\n",
        "[\n",
        "\n",
        "'Hello, how are you!',\n",
        "\n",
        "'Win money, win from home.',\n",
        "\n",
        "'Call me now',\n",
        "\n",
        "'Hello, Call you tomorrow?'\n",
        "\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVhVkoMGn_0n",
        "colab_type": "code",
        "colab": {},
        "outputId": "e16ceb2f-7b40-4a70-ac39-21dfb9b2117b"
      },
      "source": [
        "documents = ['Hello, how are you!',\n",
        "                'Win money, win from home.',\n",
        "                'Call me now.',\n",
        "                'Hello, Call you tomorrow?']\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vector = CountVectorizer()\n",
        "count_vector.fit(documents) # Fit the documents and then return the matrix\n",
        "count_vector.get_feature_names() # here the only words that we have"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['are',\n",
              " 'call',\n",
              " 'from',\n",
              " 'hello',\n",
              " 'home',\n",
              " 'how',\n",
              " 'me',\n",
              " 'money',\n",
              " 'now',\n",
              " 'tomorrow',\n",
              " 'win',\n",
              " 'you']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSh7geKcn_0p",
        "colab_type": "code",
        "colab": {},
        "outputId": "75eda1ba-bea9-4357-cc01-3fa3b97a78f6"
      },
      "source": [
        "doc_array =count_vector.transform(documents) # here we transform the text to the Bag of Words\n",
        "doc_array.toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
              "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXNmEksXn_0s",
        "colab_type": "text"
      },
      "source": [
        "let's convert it to more understandable way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDz_y-Aon_0t",
        "colab_type": "code",
        "colab": {},
        "outputId": "beebfd70-9b95-46bb-a137-709e7070f281"
      },
      "source": [
        "frequency_matrix = pd.DataFrame(doc_array.toarray(), columns=count_vector.get_feature_names())\n",
        "frequency_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>are</th>\n",
              "      <th>call</th>\n",
              "      <th>from</th>\n",
              "      <th>hello</th>\n",
              "      <th>home</th>\n",
              "      <th>how</th>\n",
              "      <th>me</th>\n",
              "      <th>money</th>\n",
              "      <th>now</th>\n",
              "      <th>tomorrow</th>\n",
              "      <th>win</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   are  call  from  hello  home  how  me  money  now  tomorrow  win  you\n",
              "0    1     0     0      1     0    1   0      0    0         0    0    1\n",
              "1    0     0     1      0     1    0   0      1    0         0    2    0\n",
              "2    0     1     0      0     0    0   1      0    1         0    0    0\n",
              "3    0     1     0      1     0    0   0      0    0         1    0    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5xtGrcVn_0w",
        "colab_type": "text"
      },
      "source": [
        "Congratulations! You have successfully implemented a Bag of Words problem for a document dataset that we created."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51okfebVn_0w",
        "colab_type": "text"
      },
      "source": [
        "## Step 3.1: Training and Testing sets\n",
        "\n",
        "Now that we have understood how to deal with the BOW problem we can get back to our dataset and split it to train and test to use it with our model.\n",
        "\n",
        "   **TODO:**  Split the dataset into a training and testing set by using the `train_test_split` method in sklearn. Split the data using the following variables:\n",
        "\n",
        "   * X_train is our training data for the 'message' column.\n",
        "   * y_train is our training data for the 'label' column\n",
        "   * X_test is our testing data for the 'message' column.\n",
        "   * y_test is our testing data for the 'label' column Print out the number of rows we have in each our training and testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLVNuIldn_0x",
        "colab_type": "code",
        "colab": {},
        "outputId": "21e400d9-cb04-4fbc-d4ac-2032dc190bc2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['message'], \n",
        "                                                    df['label'], \n",
        "                                                    random_state=1)\n",
        "\n",
        "print('Number of rows in the total set: {}'.format(df.shape[0]))\n",
        "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
        "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows in the total set: 5572\n",
            "Number of rows in the training set: 4179\n",
            "Number of rows in the test set: 1393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI7eFpG9n_00",
        "colab_type": "text"
      },
      "source": [
        "# Step 3.2: Applying Bag of Words processing to our dataset.\n",
        "\n",
        "our mission now is to apply BoW in our dataset as we did before using `CountVectorizer()`.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* Fit our training data(X_train) into CountVectorizer() and return the matrix.\n",
        "* we have to transform our testing data(X_test) to return the matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TlX5q6in_01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the CountVectorizer method\n",
        "count_vector = CountVectorizer()\n",
        "\n",
        "# Fit the training data and then return the matrix\n",
        "training_data = count_vector.fit_transform(X_train) # Fit will make it as dictionry of words\n",
        "\n",
        "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
        "testing_data = count_vector.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpDYoEB8n_03",
        "colab_type": "code",
        "colab": {},
        "outputId": "7fefe058-4e1d-4a19-fee5-e3fbfbcdbb02"
      },
      "source": [
        "print(\"The shape of the BoW is {} rows(sentences) and {} columns(features)\".format(training_data.shape[0],training_data.shape[1]))\n",
        "\n",
        "# we have to pass the features into the neural network so let's get the number of features\n",
        "input_shape = training_data.shape[1] \n",
        "print(\"The input shape is the features number which is \",input_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the BoW is 4179 rows(sentences) and 7496 columns(features)\n",
            "The input shape is the features number which is  7496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBqfvGlrn_06",
        "colab_type": "text"
      },
      "source": [
        "## Step4: Deep learning implementation using Keras\n",
        "We will be using Deep neural networks to solve this binary classification challnage.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk2RlKO8n_06",
        "colab_type": "code",
        "colab": {},
        "outputId": "b4f4b803-5afb-4418-fcce-d104f3db0165"
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvuPZWsVn_09",
        "colab_type": "text"
      },
      "source": [
        "## Build The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pHS0Nfyn_0-",
        "colab_type": "code",
        "colab": {},
        "outputId": "c8017f31-f9fb-4b97-f79f-6023ed56b794"
      },
      "source": [
        "print(\"The training data shape = \",training_data.shape)\n",
        "input_shape = training_data.shape[1] # The columns are the number of features\n",
        "print(\"The number of features in our dataset = \",input_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training data shape =  (4179, 7496)\n",
            "The number of features in our dataset =  7496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c32Mvdin_1B",
        "colab_type": "code",
        "colab": {},
        "outputId": "e914020c-34be-4cea-c63f-e1e517ba773a"
      },
      "source": [
        "# Build The structure of Model\n",
        "model = keras.Sequential() \n",
        "# here we define 20 nodes with input shape 7496 and activation function called relu\n",
        "model.add(keras.layers.Dense(20, input_shape=(input_shape,), activation='relu')) \n",
        "# then the output 1 node because we have binary classifiaction (spam/ notspam) and the activation function called sigmoid \n",
        "model.add(keras.layers.Dense(1, activation='sigmoid')) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "une_780Nn_1D",
        "colab_type": "code",
        "colab": {},
        "outputId": "657417a9-8e18-4da5-a801-30071079fa49"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # define the loss and the optimizer\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 20)                149940    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 149,961\n",
            "Trainable params: 149,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufBDS7d_n_1G",
        "colab_type": "text"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NS_t03dn_1H",
        "colab_type": "code",
        "colab": {},
        "outputId": "74f6d35f-e8ff-4c42-8348-6acf9ff053de"
      },
      "source": [
        "# pass the training data, training_labels(Y_train), define the epochs, the validation data\n",
        "model.fit(training_data, y_train, epochs=10, \n",
        "          validation_data=(testing_data, y_test),\n",
        "          verbose=1) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Ahmed\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Train on 4179 samples, validate on 1393 samples\n",
            "Epoch 1/10\n",
            "4179/4179 [==============================] - 2s 464us/step - loss: 0.3390 - acc: 0.9215 - val_loss: 0.1503 - val_acc: 0.9813\n",
            "Epoch 2/10\n",
            "4179/4179 [==============================] - 1s 320us/step - loss: 0.0971 - acc: 0.9852 - val_loss: 0.0807 - val_acc: 0.9856\n",
            "Epoch 3/10\n",
            "4179/4179 [==============================] - 1s 308us/step - loss: 0.0466 - acc: 0.9933 - val_loss: 0.0613 - val_acc: 0.9864\n",
            "Epoch 4/10\n",
            "4179/4179 [==============================] - 1s 287us/step - loss: 0.0267 - acc: 0.9966 - val_loss: 0.0535 - val_acc: 0.9878\n",
            "Epoch 5/10\n",
            "4179/4179 [==============================] - 1s 279us/step - loss: 0.0167 - acc: 0.9981 - val_loss: 0.0506 - val_acc: 0.9885\n",
            "Epoch 6/10\n",
            "4179/4179 [==============================] - 1s 264us/step - loss: 0.0113 - acc: 0.9990 - val_loss: 0.0485 - val_acc: 0.9892\n",
            "Epoch 7/10\n",
            "4179/4179 [==============================] - 1s 272us/step - loss: 0.0081 - acc: 0.9993 - val_loss: 0.0486 - val_acc: 0.9885\n",
            "Epoch 8/10\n",
            "4179/4179 [==============================] - 1s 271us/step - loss: 0.0062 - acc: 0.9995 - val_loss: 0.0492 - val_acc: 0.9885\n",
            "Epoch 9/10\n",
            "4179/4179 [==============================] - 1s 255us/step - loss: 0.0049 - acc: 0.9995 - val_loss: 0.0497 - val_acc: 0.9885\n",
            "Epoch 10/10\n",
            "4179/4179 [==============================] - 1s 262us/step - loss: 0.0040 - acc: 0.9995 - val_loss: 0.0503 - val_acc: 0.9885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x26577876b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnPeKBfwn_1K",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0n66QJYn_1M",
        "colab_type": "code",
        "colab": {},
        "outputId": "ce42182a-fe8d-4718-9ba8-afd3cd7b276e"
      },
      "source": [
        "training_loss, accuracy1 = model.evaluate(training_data, y_train)\n",
        "testing_loss, accuracy2 = model.evaluate(testing_data, y_test)\n",
        "print(\"The training loss = {:2f},  and the accuracy = {:2f}\".format(training_loss, accuracy1))\n",
        "print(\"The testing loss = {:2f},  and the accuracy = {:2f}\".format(testing_loss, accuracy2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4179/4179 [==============================] - 0s 111us/step\n",
            "1393/1393 [==============================] - 0s 112us/step\n",
            "The training loss = 0.001443,  and the accuracy = 0.999521\n",
            "The testing loss = 0.058221,  and the accuracy = 0.988514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkmJHttWn_1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "535tYYY5n_1W",
        "colab_type": "text"
      },
      "source": [
        "## Save the model and the Bow\n",
        " We'll save the model in **h5** format which contains the model architecture and the weigths of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfwXgSn-n_1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"SpamDetector.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcS-4YmHn_1a",
        "colab_type": "text"
      },
      "source": [
        "## Load the model and using it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viZQOJT6n_1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxOCYL4Nn_1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model = load_model(\"SpamDetector.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd0LqO1Nn_1g",
        "colab_type": "text"
      },
      "source": [
        "### To save the BoW we need to save the feature names to fit them again when we use the model\n",
        "\n",
        "We can use `pickle` module for that. This module have two methods,\n",
        "\n",
        "Pickling(dump): Convert Python objects into string representation.\n",
        "\n",
        "Unpickling(load): Retrieving original objects from stored string representstion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnZFD5QJn_1g",
        "colab_type": "code",
        "colab": {},
        "outputId": "c46ceaf5-8183-4302-c5c3-b63543d6ca6c"
      },
      "source": [
        "print(\"The length of the bow = \",len(count_vector.get_feature_names()))\n",
        "print(\"-\"*30)\n",
        "print(\"some samples of the data : \")\n",
        "count_vector.get_feature_names()[720:730]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the bow =  7496\n",
            "------------------------------\n",
            "some samples of the data : \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abj',\n",
              " 'able',\n",
              " 'abnormally',\n",
              " 'about',\n",
              " 'aboutas',\n",
              " 'abroad',\n",
              " 'absolutely',\n",
              " 'absolutly',\n",
              " 'abstract',\n",
              " 'abt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl9chCyMn_1j",
        "colab_type": "text"
      },
      "source": [
        "Let's save the feature names into file to use it for applying bow again without load The data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7DgcfVrn_1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"bow_featureNames.txt\", \"wb\") as fp:   #Pickling\n",
        "    pickle.dump(count_vector.get_feature_names(), fp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfSURqiun_1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_bow(message):\n",
        "    with open(\"bow_featureNames.txt\", \"rb\") as fp:   # Unpickling\n",
        "        loaded_names = pickle.load(fp)\n",
        "        count_vector = CountVectorizer()\n",
        "        fit_bow = count_vector.fit(loaded_names)\n",
        "        return count_vector.transform(message)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCZR5GnKn_1q",
        "colab_type": "text"
      },
      "source": [
        "## Build code to predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZafp5ntn_1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spam_detector(message):\n",
        "    msg = []\n",
        "    msg.append(message)\n",
        "    bow = fit_bow(msg)\n",
        "    predicting = model.predict(bow)\n",
        "    if float(predicting)*100 > 0.4:\n",
        "        return \"Spam\"\n",
        "    else:\n",
        "        return \"Not Spam\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4d0ZXyxn_1u",
        "colab_type": "code",
        "colab": {},
        "outputId": "ce01f72c-1f48-4802-802d-2c95fe05850a"
      },
      "source": [
        "x = \"free cash just sign in\"\n",
        "spam_detector(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Spam'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9p8jXppn_1w",
        "colab_type": "code",
        "colab": {},
        "outputId": "cb7e6355-63fb-4b0d-ba6c-943e027b4dec"
      },
      "source": [
        "y = \"take this cash and buy a dinner\"\n",
        "spam_detector(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Not Spam'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2RCuj--n_1z",
        "colab_type": "text"
      },
      "source": [
        "##### Congratulations! You have successfully designed a model that can predict if an message is spam or not!\n",
        "##### Thanks for reach The eand"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ9HRQrFn_10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XkXUXwDn_13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBZ3yJIun_15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}